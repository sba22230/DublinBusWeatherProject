{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reqPkgs = ['matplotlib', 'scipy', 'statsmodels', 'pandas', 'numpy', 'functools', 'ipython'\n",
    ",'ipywidgets', 'seaborn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "reqs = subprocess.check_output([sys.executable, '-m', 'pip', 'freeze'])\n",
    "installed_packages = [r.decode().split('==')[0] for r in reqs.split()]\n",
    "print(installed_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instPks = list(set(reqPkgs) - set(installed_packages))\n",
    "print(instPks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "%pip install statsmodels\n",
    "%pip install ipywidgets\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in instPks:\n",
    "    %pip install p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.stats as stats\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from functools import partial\n",
    "import IPython\n",
    "import ipywidgets\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import interact, interactive,fixed\n",
    "import operator\n",
    "from IPython.display import Javascript, display,HTML\n",
    "from ipywidgets import widgets, VBox\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import getpass\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ConfUtility():   \n",
    "    @staticmethod\n",
    "    def parse_yaml(input_file):\n",
    "        import yaml\n",
    "        yaml_dict = {}\n",
    "        with open (input_file,'r') as fin:\n",
    "            try:\n",
    "                yaml_dict = yaml.load(fin)\n",
    "            except Exception as ex:\n",
    "                print (ex)\n",
    "        return yaml_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def dict_to_htmllist(dc, include_list=None):\n",
    "        dc2 = {}\n",
    "        output_formatting = {'Target':'Target variable is ','CategoricalColumns':'Categorical Columns are ',\n",
    "                           'NumericalColumns':'Numerical Columns are '}\n",
    "        for each in dc.keys():\n",
    "            if not include_list or each in include_list:\n",
    "                if isinstance(dc[each],  collections.Iterable) and not isinstance(dc[each], str):\n",
    "                    dc2[each] = ', \\n'.join(val for val in dc[each])\n",
    "                else:\n",
    "                    dc2[each] = dc[each]\n",
    "        html_list = \"<ul>{}</ul>\"\n",
    "        html_list_entry = \"<li>{}</li>\"\n",
    "        output3 = ''\n",
    "\n",
    "        for each in set(include_list)|set(dc2.keys()):\n",
    "            output3 += html_list_entry.format(output_formatting[each]+dc2[each])\n",
    "        html_list = html_list.format(output3)\n",
    "        return HTML(html_list)\n",
    "    \n",
    "class InteractionAnalytics():\n",
    "    @staticmethod\n",
    "    def rank_associations(df, conf_dict, col1, col2, col3):        \n",
    "        try:\n",
    "            col2 = int(col2)\n",
    "            col3 = int(col3)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Passed Variable is Numerical\n",
    "        if (col1 in NumericalColumns):\n",
    "            fig,(ax1,ax2) = plt.subplots(1, 2)\n",
    "            if len(NumericalColumns)>1:\n",
    "                \n",
    "                # Interaction with numerical variables\n",
    "                df2 = df[NumericalColumns]\n",
    "                corrdf = df2.corr()\n",
    "                corrdf = abs(corrdf) \n",
    "                corrdf2 = corrdf[corrdf.index==col1].reset_index()[[each for each in corrdf.columns \\\n",
    "                                                      if col1 not in each]].unstack().sort_values(kind=\"quicksort\", \n",
    "                                                                                                  ascending=False).head(col2)\n",
    "                corrdf2 = corrdf2.reset_index()\n",
    "                corrdf2.columns = ['level0','level1','rsq']\n",
    "                corrdf2.set_index('level0', inplace=True)\n",
    "                corrdf2[['rsq']].plot(kind='bar', ax=ax1)\n",
    "                ax1.legend().set_visible(False)\n",
    "                ax1.set_xlabel('Absolute Correlation')\n",
    "                ax1.set_title('Top {} Associated Numeric Variables'.format(str(col2)))\n",
    "                # Interaction with categorical variables\n",
    "                etasquared_dict = {}\n",
    "            if len(CategoricalColumns) >= 1:\n",
    "                for each in CategoricalColumns:\n",
    "                    mod = ols('{} ~ C({})'.format(col1, each),data=df[[col1,each]],missing='drop').fit()\n",
    "                    aov_table = sm.stats.anova_lm(mod, typ=1)\n",
    "                    esq_sm = aov_table['sum_sq'][0]/(aov_table['sum_sq'][0]+aov_table['sum_sq'][1])\n",
    "                    etasquared_dict[each] = esq_sm\n",
    "\n",
    "                topk_esq = pd.DataFrame.from_dict(etasquared_dict, orient='index').unstack().sort_values(\\\n",
    "                    kind = 'quicksort', ascending=False).head(col3).reset_index().set_index('level_1')\n",
    "                topk_esq.columns = ['level_0', 'EtaSquared']\n",
    "                topk_esq[['EtaSquared']].plot(kind='bar',ax=ax2)\n",
    "                ax2.legend().set_visible(False)\n",
    "                ax2.set_xlabel('Eta-squared values')\n",
    "                ax2.set_title('Top {}  Associated Categoric Variables'.format(str(col2)))\n",
    "        # Passed Variable is Categorical\n",
    "        else:\n",
    "            #Interaction with numerical variables\n",
    "            fig,(ax1,ax2) = plt.subplots(1,2)\n",
    "            if len(NumericalColumns) >= 1:\n",
    "                etasquared_dict = {}\n",
    "                for each in NumericalColumns:\n",
    "                    mod = ols('{} ~ C({})'.format(each, col1), data = df[[col1,each]]).fit()\n",
    "                    aov_table = sm.stats.anova_lm(mod, typ=1)\n",
    "                    esq_sm = aov_table['sum_sq'][0]/(aov_table['sum_sq'][0]+aov_table['sum_sq'][1])\n",
    "                    etasquared_dict[each] = esq_sm\n",
    "\n",
    "                topk_esq = pd.DataFrame.from_dict(etasquared_dict, orient='index').unstack().sort_values(\\\n",
    "                    kind = 'quicksort', ascending=False).head(col2).reset_index().set_index('level_1')\n",
    "                topk_esq.columns = ['level_0','EtaSquared']\n",
    "                topk_esq[['EtaSquared']].plot(kind='bar',ax=ax1)\n",
    "                ax1.legend().set_visible(False)\n",
    "                ax1.set_xlabel('Eta-squared values')\n",
    "                ax1.set_title('Top {} Associated Numeric Variables'.format(str(col2)))\n",
    "\n",
    "            # Interaction with categorical variables\n",
    "            cramer_dict = {}\n",
    "            if len(CategoricalColumns)>1:\n",
    "                for each in CategoricalColumns:\n",
    "                    if each !=col1:\n",
    "                        tbl = pd.crosstab(df[col1], df[each])\n",
    "                        chisq = stats.chi2_contingency(tbl, correction=False)[0]\n",
    "                        try:\n",
    "                            cramer = np.sqrt(chisq/sum(tbl))\n",
    "                        except:\n",
    "                            cramer = np.sqrt(chisq/tbl.as_matrix().sum())\n",
    "                            pass\n",
    "                        cramer_dict[each] = cramer\n",
    "\n",
    "                topk_cramer = pd.DataFrame.from_dict(cramer_dict, orient='index').unstack().sort_values(\\\n",
    "                    kind = 'quicksort', ascending=False).head(col3).reset_index().set_index('level_1')\n",
    "                topk_cramer.columns = ['level_0','CramersV']\n",
    "                topk_cramer[['CramersV']].plot(kind='bar',ax=ax2)\n",
    "                ax2.legend().set_visible(False)\n",
    "                ax2.set_xlabel(\"Cramer's V\")\n",
    "                ax2.set_title('Top {} Associated Categoric Variables'.format(str(col2)))\n",
    "        \n",
    "    @staticmethod\n",
    "    def NoLabels(x):\n",
    "        return ''\n",
    "    \n",
    "    @staticmethod\n",
    "    def categorical_relations(df, col1, col2):\n",
    "        if col1 != col2:\n",
    "            df2 = df[(df[col1].isin(df[col1].value_counts().head(10).index.tolist()))&(df[col2].isin(df[col2].value_counts().head(10).index.tolist())) ]\n",
    "            df3 = pd.crosstab(df2[col1], df2[col2])\n",
    "            df3 = df3+1e-8\n",
    "        else:\n",
    "            df3 = pd.DataFrame(df[col1].value_counts())[:10]\n",
    "        fig,ax = plt.subplots()\n",
    "        fig,rects = mosaic(df3.unstack(),ax=ax, statistic=False, labelizer=InteractionAnalytics.NoLabels, label_rotation=30)\n",
    "        ax.set_ylabel(col1)\n",
    "        ax.set_xlabel(col2)\n",
    "        ax.set_title('{} vs {}'.format(col1, col2) )\n",
    "    \n",
    "    @staticmethod\n",
    "    def numerical_relations(df, col1, col2):\n",
    "        from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "        x = df[col2]\n",
    "        y = df[col1]\n",
    "        f, ax = plt.subplots(1)\n",
    "\n",
    "        # lowess\n",
    "        ax.scatter(x, y, c='g', s=6)\n",
    "        lowess_results = lowess(y, x)#[:,1]\n",
    "        xs = lowess_results[:, 0]\n",
    "        ys = lowess_results[:, 1]\n",
    "        ax.plot(xs,ys,'red',linewidth=1)\n",
    "\n",
    "        #ols\n",
    "        fit = np.polyfit(x, y, 1)\n",
    "        fit1d = np.poly1d(fit)\n",
    "        ax.plot(x, fit1d(x), '--b')\n",
    "        ax.set_xlabel(col2)\n",
    "        ax.set_ylabel(col1)\n",
    "        corr = round(scipy.stats.pearsonr(x, y)[0], 6)\n",
    "        ax.set_title('{} vs {}, Correlation {}'.format(col1, col2, corr))\n",
    "    \n",
    "    @staticmethod\n",
    "    def numerical_correlation(df, conf_dict, col1):\n",
    "        from matplotlib.pyplot import quiver, colorbar, clim,  matshow\n",
    "        df2 = df[NumericalColumns].corr(method=col1)\n",
    "        col_names = list(df[NumericalColumns].columns)\n",
    "        fig,ax = plt.subplots(1, 1)\n",
    "        m = ax.matshow(df2, cmap=matplotlib.pyplot.cm.coolwarm)\n",
    "        ax.grid(b=False)\n",
    "        fig.colorbar(m)\n",
    "        ax.set_xticklabels([' '] + col_names) \n",
    "        ax.set_yticklabels([' '] + col_names)\n",
    "\n",
    "    @staticmethod\n",
    "    def numerical_pca(df, conf_dict, col1, col2, col3):\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        num_numeric = len(NumericalColumns)\n",
    "        num_pca = num_numeric\n",
    "        xticklabels = ['']\n",
    "        for i in range(1,num_pca+1):\n",
    "            xticklabels+=['Comp'+str(i)]\n",
    "            xticklabels+=['']\n",
    "        df2 = df[NumericalColumns]\n",
    "        X = StandardScaler().fit_transform(df2.values)\n",
    "        pca = PCA(n_components=num_pca)\n",
    "        pca.fit(X)\n",
    "        fig, (ax1,ax2) = plt.subplots(1, 2)\n",
    "        ax1.bar(np.arange(1,(num_numeric+1),1),pca.explained_variance_ratio_ )\n",
    "        ax1.set_ylabel('% Variance Explained')\n",
    "        ax1.set_xticklabels(xticklabels)\n",
    "        x_pca_index = int(col2) - 1\n",
    "        y_pca_index = int(col3) - 1\n",
    "        Y_pca = pd.DataFrame(pca.fit_transform(X))\n",
    "        Y_pca_labels = []\n",
    "        for i in range(1,num_pca+1):\n",
    "            Y_pca_labels.append('PC'+str(i))\n",
    "        Y_pca.columns = Y_pca_labels       \n",
    "        Y_pca[col1] = df[col1]\n",
    "        colors_dict = {}\n",
    "        colors_list = ['r', 'y', 'c', 'y', 'k']\n",
    "        j = 0\n",
    "        for i in np.unique(df[col1]):\n",
    "            colors_dict[i] = colors_list[j]\n",
    "            j += 1\n",
    "            if j == len(colors_list):\n",
    "                j = 0\n",
    "        colordf = pd.DataFrame.from_dict(colors_dict, orient='index').reset_index()\n",
    "        colordf.columns = [col1, 'color']\n",
    "        merged_df = pd.merge(colordf,Y_pca)\n",
    "        grouped_df = merged_df.groupby(col1)\n",
    "        for name, group in grouped_df:\n",
    "            ax2.scatter(\n",
    "               group[Y_pca.columns[x_pca_index]], group[Y_pca.columns[y_pca_index]],label=name,  \n",
    "               c=group['color'],                            \n",
    "               marker='o',                                \n",
    "               s=6)                                       \n",
    "        ax2.set_xlabel(Y_pca.columns[x_pca_index])\n",
    "        ax2.set_ylabel(Y_pca.columns[y_pca_index])\n",
    "        ax2.legend(title=col1, fontsize=14)\n",
    "                \n",
    "    @staticmethod\n",
    "    def nc_relation(df, conf_dict, col1, col2, col3=None):\n",
    "        fig,ax = plt.subplots()\n",
    "        f = df[[col1,col2]].boxplot(by=col2, ax=ax)\n",
    "        mod = ols('{} ~ {}'.format(col1, col2), data=df[[col1, col2]]).fit()\n",
    "        aov_table = sm.stats.anova_lm(mod, typ=1)\n",
    "        p_val = round(aov_table['PR(>F)'][0], 6)\n",
    "        status = 'Passed'\n",
    "        color = 'blue'\n",
    "        if p_val < 0.05:\n",
    "            status = 'Rejected'\n",
    "            color = 'red'\n",
    "        fig.suptitle('ho {} (p_value = {})'.format( status, p_val), color=color, fontsize=10)\n",
    "    \n",
    "    @staticmethod\n",
    "    def pca_3d(df, conf_dict, col1, col2,  col3=None):\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        df2 = df[NumericalColumns]\n",
    "        X = StandardScaler().fit_transform(df2.values)\n",
    "        pca = PCA(n_components=4)\n",
    "        pca.fit(X)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "        ax.view_init(elev=10, azim=int(col2))              \n",
    "        Y_pca = pd.DataFrame(pca.fit_transform(X))\n",
    "        Y_pca.columns = ['PC1','PC2','PC3','PC4']\n",
    "        Y_pca[col1] = df[col1]\n",
    "        colors_dict = {}\n",
    "        colors_list = ['r', 'y', 'c', 'y', 'k']\n",
    "        j = 0\n",
    "        for i in np.unique(df[col1]):\n",
    "            colors_dict[i] = colors_list[j]\n",
    "            j += 1\n",
    "            if j == len(colors_list):\n",
    "                j = 0\n",
    "        colordf = pd.DataFrame.from_dict(colors_dict, orient='index').reset_index()\n",
    "        colordf.columns = [col1,'color']\n",
    "        merged_df = pd.merge(colordf,Y_pca)\n",
    "        grouped_df = merged_df.groupby(col1)\n",
    "        for name, group in grouped_df:\n",
    "            ax.scatter(\n",
    "               group['PC1'], group['PC2'], group['PC3'], label=name,  \n",
    "               c = group['color'],                            \n",
    "               marker = 'o',                                \n",
    "               s=6)                                      \n",
    "        ax.set_xlabel('PC1', labelpad=18)\n",
    "        ax.set_ylabel('PC2', labelpad=18)\n",
    "        ax.set_zlabel('PC3', labelpad=18)\n",
    "        ax.legend(title=col1, fontsize=10)\n",
    "\n",
    "    @staticmethod\n",
    "    def pca_3d_new(df, conf_dict, col1, col2, col3, col4, col5):\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        df2 = df[NumericalColumns]\n",
    "        X = StandardScaler().fit_transform(df2.values)\n",
    "        num_numeric = len(NumericalColumns)\n",
    "        pca = PCA(n_components=num_numeric)\n",
    "        pca.fit(X)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "        ax.view_init(elev=10, azim=int(col5))                 \n",
    "        Y_pca = pd.DataFrame(pca.fit_transform(X))\n",
    "        Y_pca_names = []\n",
    "        for i in range(1, num_numeric+1):\n",
    "            Y_pca_names.append('PC'+str(i))\n",
    "        Y_pca.columns = Y_pca_names\n",
    "        Y_pca[col1] = df[col1]\n",
    "        colors_dict = {}\n",
    "        colors_list = ['r', 'y', 'c', 'y', 'k']\n",
    "        j = 0\n",
    "        for i in np.unique(df[col1]):\n",
    "            colors_dict[i] = colors_list[j]\n",
    "            j += 1\n",
    "            if j == len(colors_list):\n",
    "                j = 0\n",
    "        colordf = pd.DataFrame.from_dict(colors_dict, orient='index').reset_index()\n",
    "        colordf.columns = [col1,'color']\n",
    "        merged_df = pd.merge(colordf,Y_pca)\n",
    "        grouped_df = merged_df.groupby(col1)\n",
    "        for name, group in grouped_df:\n",
    "            ax.scatter(\n",
    "               group[Y_pca_names[int(col2)-1]], group[Y_pca_names[int(col3)-1]], group[Y_pca_names[int(col4)-1]], label=name,  \n",
    "               c = group['color'],                            \n",
    "               marker = 'o',                                \n",
    "               s=6)\n",
    "        ax.set_xlabel(Y_pca_names[int(col2)-1], labelpad=18)\n",
    "        ax.set_ylabel(Y_pca_names[int(col3)-1], labelpad=18)\n",
    "        ax.set_zlabel(Y_pca_names[int(col4)-1], labelpad=18)\n",
    "        ax.legend(title=col1, fontsize=10)\n",
    "        \n",
    "    @staticmethod\n",
    "    def nnc_relation(df, conf_dict, col1, col2, col3):\n",
    "        import itertools\n",
    "        markers = ['x', 'o', '^']\n",
    "        color = itertools.cycle(['r', 'y', 'c', 'y', 'k']) \n",
    "        groups = df[[col1, col2, col3]].groupby(col3)\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.margins(0.05) \n",
    "\n",
    "        for (name, group), marker in zip(groups, itertools.cycle(markers)):\n",
    "            ax.plot(group[col1], group[col2], marker='o', linestyle='', ms=4, label=name)\n",
    "        ax.set_xlabel(col1)\n",
    "        ax.set_ylabel(col2)\n",
    "        ax.legend(numpoints=1, loc='best', title=col3)\n",
    "        \n",
    "class TargetAnalytics():\n",
    "    ReportedVariables = []\n",
    "    @staticmethod\n",
    "    def custom_barplot(df, col1=''):\n",
    "        f, (ax0,ax1) = plt.subplots(1, 2)\n",
    "        df[col1].value_counts().plot(ax=ax0, kind='bar')\n",
    "        ax0.set_title('Bar Plot of {}'.format(col1))\n",
    "        df[col1].value_counts().plot(ax=ax1, kind='pie')\n",
    "        ax1.set_title('Pie Chart of {}'.format(col1))\n",
    "\n",
    "class NumericAnalytics():\n",
    "    @staticmethod\n",
    "    def shapiro_test(x):\n",
    "        p_val = round(stats.shapiro(x)[1],6)\n",
    "        status = 'passed'\n",
    "        color = 'blue'\n",
    "        if p_val < 0.05:\n",
    "            status = 'failed'\n",
    "            color = 'red'\n",
    "        return status, color, p_val\n",
    "\n",
    "    @staticmethod\n",
    "    def custom_barplot(df, col1=''):\n",
    "        fig, axes = plt.subplots(2,2)\n",
    "        axes = axes.reshape(-1)\n",
    "        df[col1].plot(ax=axes[0], kind='hist')\n",
    "        axes[0].set_title('Histogram of {}'.format(col1))\n",
    "        df[col1].plot(ax=axes[1], kind='kde')\n",
    "        axes[1].set_title('Density Plot of {}'.format(col1))\n",
    "        ax3 = plt.subplot(223)\n",
    "        stats.probplot(df[col1], plot=plt)\n",
    "        axes[2].set_title('QQ Plot of {}'.format(col1))\n",
    "        df[col1].plot(ax=axes[3], kind='box')\n",
    "        axes[3].set_title('Box Plot of {}'.format(col1))\n",
    "        status, color, p_val = NumericAnalytics.shapiro_test(df[col1])\n",
    "        fig.suptitle('Normality test for {} {} (p_value = {})'.format(col1, status, round(p_val, 6)), color=color, fontsize=12)\n",
    "    \n",
    "class CategoricAnalytics():\n",
    "    @staticmethod\n",
    "    def custom_barplot(df, col1=''):\n",
    "        f, (ax0,ax1) = plt.subplots(1,2)\n",
    "        df[col1].value_counts().nlargest(10).plot(ax=ax0, kind='bar')\n",
    "        ax0.set_xlabel(col1)\n",
    "        ax0.set_title('Bar chart of {}'.format(col1))\n",
    "        df[col1].value_counts().nlargest(10).plot(ax=ax1, kind='pie')\n",
    "        ax1.set_title('Pie chart of {}'.format(col1))\n",
    " \n",
    "%matplotlib inline\n",
    "font={'family':'normal','weight':'normal','size':8}\n",
    "matplotlib.rc('font',**font)\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 5.0)\n",
    "matplotlib.rc('xtick', labelsize=9) \n",
    "matplotlib.rc('ytick', labelsize=9)\n",
    "matplotlib.rc('axes', labelsize=10)\n",
    "matplotlib.rc('axes', titlesize=10)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"read and summarize\"></a> Read and Summarize the Data\n",
    "\n",
    "### Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = './Data/Bus/Gz/siri.20130101.csv.gz'\n",
    "df = pd.read_csv(data_file, compression='gzip')\n",
    "\n",
    "df.columns = ['Timestamp', 'Line ID', 'Direction', 'Journey Pattern ID', 'Time Frame', 'Vehicle Journey ID', 'Operator', 'Congestion', 'Lon WGS84', 'Lat WGS84', 'Delay', 'Block ID', 'Vehicle ID', 'Stop ID', 'At Stop']\n",
    "#remove the space in column names\n",
    "df.columns = [x.strip().replace(' ', '') for x in df.columns]\n",
    "\n",
    "# Getting the list of categorical columns if it was not there in the yaml file\n",
    "CategoricalColumns = list(set(list(df.select_dtypes(exclude=[np.number]).columns)))\n",
    "\n",
    "NumericalColumns = list(set(list(df.select_dtypes([np.number]).columns)))\n",
    "\n",
    "\n",
    "df = pd.read_parquet('./Data/Bus/CleanedBusData.parquet')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Columns and column types -- correct/modify as necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CategoricalColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NumericalColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclude columns that we do not need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnsToExclude = ['JourneyPatternID', 'StopID']\n",
    "CategoricalColumns = list(set(CategoricalColumns) - set(ColumnsToExclude))\n",
    "NumericalColumns = list(set(NumericalColumns)-set(ColumnsToExclude))\n",
    "\n",
    "Target = 'Congestion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(ColumnsToExclude, axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the dimensions of the data (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The data has {} Rows and {} columns'.format(df.shape[0],df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the dimensions of the data (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ','.join(each for each in list(df.columns))\n",
    "print(\"The column names are:\" + col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The types of columns are:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"descriptive statistics\"></a>Extract Descriptive Statistics of Each Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_missing(x):\n",
    "    return len(x.index)-x.count()\n",
    "\n",
    "def num_unique(x):\n",
    "    return len(np.unique(x))\n",
    "\n",
    "temp_df = df.describe().T\n",
    "missing_df = pd.DataFrame(df.apply(num_missing, axis=0)) \n",
    "missing_df.columns = ['missing']\n",
    "unq_df = pd.DataFrame(df.apply(num_unique, axis=0))\n",
    "unq_df.columns = ['unique']\n",
    "types_df = pd.DataFrame(df.dtypes)\n",
    "types_df.columns = ['DataType']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the descriptive statistics of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_df = temp_df.join(missing_df).join(unq_df).join(types_df)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the descriptive statistics of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(types_df.index)\n",
    "num_cols = len(col_names)\n",
    "index = range(num_cols)\n",
    "cat_index = []\n",
    "for i in index:\n",
    "    if col_names[i] in CategoricalColumns:\n",
    "        cat_index.append(i)\n",
    "summary_df_cat = missing_df.join(unq_df).join(types_df.iloc[cat_index], how='inner') #Only summarize categorical columns\n",
    "summary_df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"individual variables\"></a>Explore Individual Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Target in CategoricalColumns:\n",
    "    w1_value = ''\n",
    "    w1 = None  \n",
    "    w1 = widgets.Dropdown(\n",
    "        options=[Target],\n",
    "        value=Target,\n",
    "        description='Target Variable:',\n",
    "    )\n",
    "    i = interactive(TargetAnalytics.custom_barplot, df=fixed(df), col1=w1)\n",
    "    hbox = widgets.HBox(i.children[:1])\n",
    "    display(hbox)\n",
    "    hbox.on_displayed(TargetAnalytics.custom_barplot(df=df, col1=w1.value))\n",
    "else:\n",
    "    w1_value = ''\n",
    "    w1 = None\n",
    "    w1 = widgets.Dropdown(\n",
    "            options=[Target],\n",
    "            value=Target,\n",
    "            description='Target Variable:',\n",
    "        )\n",
    "    i = interactive(NumericAnalytics.custom_barplot, df=fixed(df), col1=w1)\n",
    "    hbox = widgets.HBox(i.children)\n",
    "    display(hbox)\n",
    "    hbox.on_displayed(NumericAnalytics.custom_barplot(df=df, col1=w1.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore individual numeric variables and test for normality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoricalColumns = list(set(['LineID', 'Direction', 'TimeFrame', 'VehicleJourneyID', 'Operator', 'Congestion',  'Delay', 'BlockID', 'VehicleID', 'StopID', 'AtStop']))\n",
    "NumericalColumns = list(set(list(df.select_dtypes([np.number]).columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_value = ''\n",
    "w1 = None\n",
    "w1 = widgets.Dropdown(\n",
    "        options=NumericalColumns,\n",
    "        value=NumericalColumns[0],\n",
    "        description='Numeric Variable:',\n",
    "    )\n",
    "\n",
    "i = interactive(NumericAnalytics.custom_barplot, df=fixed(df), col1=w1)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(NumericAnalytics.custom_barplot(df=df, col1=w1.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore individual categorical variables (sorted by frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_value = ''\n",
    "w1 = None\n",
    "\n",
    "w1 = widgets.Dropdown(\n",
    "    options = CategoricalColumns,\n",
    "    value = CategoricalColumns[0],\n",
    "    description = 'Categorical Variable:',\n",
    ")\n",
    "\n",
    "\n",
    "i = interactive(CategoricAnalytics.custom_barplot, df=fixed(df), col1=w1)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(CategoricAnalytics.custom_barplot(df=df, col1=w1.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"multiple variables\"></a>Explore Interactions Between Variables\n",
    "### <a name=\"rank variables\"></a>Rank variables based on linear relationships with reference variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = [Target] + NumericalColumns + CategoricalColumns\n",
    "cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "w1 = widgets.Dropdown(    \n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Ref Var:'\n",
    ")\n",
    "w2 = ipywidgets.Text(value=\"5\", description='Top Num Vars:')\n",
    "w3 = ipywidgets.Text(value=\"5\", description='Top Cat Vars:')\n",
    "i = interactive(InteractionAnalytics.rank_associations, df=fixed(df),conf_dict=fixed(cols_list), col1=w1, col2=w2, col3=w3)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.rank_associations(df=df, conf_dict=cols_list, col1=w1.value, col2=w2.value, col3=w3.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"two categorical\"></a>Explore interactions between categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = None, None\n",
    "\n",
    "if Target in CategoricalColumns:\n",
    "    cols_list = [Target] + CategoricalColumns \n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "else:\n",
    "    cols_list = CategoricalColumns\n",
    "    \n",
    "w1 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Categorical Var 1:'\n",
    ")\n",
    "w2 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[1],\n",
    "    description='Categorical Var 2:'\n",
    ")\n",
    "\n",
    "i = interactive(InteractionAnalytics.categorical_relations, df=fixed(df), col1=w1, col2=w2)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.categorical_relations(df=df, col1=w1.value, col2=w2.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"two numerical\"></a>Explore interactions between numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = None, None\n",
    "\n",
    "if Target in NumericalColumns:\n",
    "    cols_list = [Target] + NumericalColumns \n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "else:\n",
    "    cols_list = NumericalColumns\n",
    "w1 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Numerical Var 1:'\n",
    ")\n",
    "w2 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[1],\n",
    "    description='Numerical Var 2:'\n",
    ")\n",
    "i = interactive(InteractionAnalytics.numerical_relations, df=fixed(df), col1=w1, col2=w2)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.numerical_relations(df, col1=w1.value, col2=w2.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore correlation matrix between numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = None\n",
    "w1 = widgets.Dropdown(\n",
    "    options=['pearson','kendall','spearman'],\n",
    "    value='pearson',\n",
    "    description='Correlation Method:'\n",
    ")\n",
    "i = interactive(InteractionAnalytics.numerical_correlation, df=fixed(df), conf_dict=fixed(cols_list), col1=w1)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.numerical_correlation(df, conf_dict=cols_list, col1=w1.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"numerical and categorical\"></a>Explore interactions between numerical and categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = None, None\n",
    "\n",
    "if Target in NumericalColumns:\n",
    "    cols_list = [Target] + NumericalColumns #Make target the default reference variable\n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) #remove variables that might be duplicates with target\n",
    "else:\n",
    "    cols_list = NumericalColumns\n",
    "    \n",
    "w1 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Numerical Variable:'\n",
    ")\n",
    "\n",
    "if Target in CategoricalColumns:\n",
    "    cols_list = [Target] + CategoricalColumns #Make target the default reference variable\n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) #remove variables that might be duplicates with target\n",
    "else:\n",
    "    cols_list = CategoricalColumns\n",
    "    \n",
    "w2 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Categorical Variable:'\n",
    ")\n",
    "i = interactive(InteractionAnalytics.nc_relation, df=fixed(df),conf_dict=fixed(cols_list), col1=w1, col2=w2, col3=fixed(w3))\n",
    "hbox = widgets.HBox(i.children)\n",
    "display( hbox )\n",
    "hbox.on_displayed(InteractionAnalytics.nc_relation(df, cols_list, col1=w1.value, col2=w2.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"two numerical and categorical\"></a>Explore interactions between two numerical variables and a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2, w3 = None, None, None\n",
    "\n",
    "if Target in NumericalColumns:\n",
    "    cols_list = [Target] + NumericalColumns \n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "else:\n",
    "    cols_list = NumericalColumns\n",
    "    \n",
    "w1 = widgets.Dropdown(\n",
    "    options = cols_list,\n",
    "    value = cols_list[0],\n",
    "    description = 'Numerical Var 1:'\n",
    ")\n",
    "w2 = widgets.Dropdown(\n",
    "    options = cols_list,\n",
    "    value = cols_list[1],\n",
    "    description = 'Numerical Var 2:'\n",
    ")\n",
    "\n",
    "if Target in CategoricalColumns:\n",
    "    cols_list = [Target] + CategoricalColumns\n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "else:\n",
    "    cols_list = CategoricalColumns\n",
    "    \n",
    "w3 = widgets.Dropdown(\n",
    "    options = cols_list,\n",
    "    value = cols_list[0],\n",
    "    description = 'Legend Cat Var:'\n",
    ")\n",
    "i = interactive(InteractionAnalytics.nnc_relation, df=fixed(df),conf_dict=fixed(cols_list), col1=w1, col2=w2, col3=w3)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.nnc_relation(df, cols_list, col1=w1.value,col2=w2.value, col3=w3.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"pca\"></a>Visualize numerical data by projecting to principal component spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project data to 2-D principal component space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_numeric = len(NumericalColumns)\n",
    "if  num_numeric > 3:\n",
    "    \n",
    "    w1, w2, w3 = None, None, None\n",
    "    if Target in CategoricalColumns:\n",
    "        cols_list = [Target] + CategoricalColumns \n",
    "        cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "    else:\n",
    "        cols_list = CategoricalColumns\n",
    "    w1 = widgets.Dropdown(\n",
    "        options = cols_list,\n",
    "        value = cols_list[0],\n",
    "        description = 'Legend Variable:',\n",
    "        width = 10\n",
    "    )\n",
    "    w2 = widgets.Dropdown(\n",
    "        options = [str(x) for x in np.arange(1,num_numeric+1)],\n",
    "        value = '1',\n",
    "        width = 1,\n",
    "        description='PC at X-Axis:'\n",
    "    )\n",
    "    w3 = widgets.Dropdown(\n",
    "        options = [str(x) for x in np.arange(1,num_numeric+1)],\n",
    "        value = '2',\n",
    "        description = 'PC at Y-Axis:'\n",
    "    )\n",
    "    i = interactive(InteractionAnalytics.numerical_pca, df=fixed(df),conf_dict=fixed(cols_list), col1=w1, col2=w2, col3=w3)\n",
    "    hbox = widgets.HBox(i.children[:3])\n",
    "    display(hbox)\n",
    "    hbox.on_displayed(InteractionAnalytics.numerical_pca(df, conf_dict=cols_list, col1=w1.value, col2=w2.value, col3=w3.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project data to 3-D principal component space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(NumericalColumns) > 3:\n",
    "    if Target in CategoricalColumns:\n",
    "        cols_list = [Target] + CategoricalColumns \n",
    "        cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "    else:\n",
    "        cols_list = CategoricalColumns\n",
    "    w1, w2 = None, None\n",
    "    w1 = widgets.Dropdown(\n",
    "        options=cols_list,\n",
    "        value=cols_list[0],\n",
    "        description='Legend Variable:'\n",
    "    )\n",
    "    w2 = ipywidgets.IntSlider(min=-180, max=180, step=5, value=30, description='Angle')\n",
    "    i = interactive(InteractionAnalytics.pca_3d, df=fixed(df), conf_dict=fixed(cols_list),col1=w1, col2=w2, col3=fixed(w3))\n",
    "    hbox=widgets.HBox(i.children[:2])\n",
    "    display(hbox)\n",
    "    hbox.on_displayed(InteractionAnalytics.pca_3d(df,cols_list,col1=w1.value,col2=w2.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a08fcf68f6d29b2326135a6912241a007a7785b998dba888347c81b585e1afa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
