{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "reqPkgs = ['matplotlib', 'scipy', 'statsmodels', 'pandas', 'numpy', 'functools', 'ipython'\n",
    ",'ipywidgets', 'seaborn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asttokens', 'backcall', 'certifi', 'charset-normalizer', 'colorama', 'contourpy', 'cycler', 'debugpy', 'decorator', 'entrypoints', 'executing', 'fonttools', 'idna', 'ipykernel', 'ipyparallel', 'ipython', 'ipywidgets', 'jedi', 'joblib', 'jupyter_client', 'jupyter_core', 'jupyterlab-widgets', 'kiwisolver', 'matplotlib', 'matplotlib-inline', 'nest-asyncio', 'numpy', 'packaging', 'pandas', 'parso', 'pickleshare', 'Pillow', 'prompt-toolkit', 'psutil', 'pure-eval', 'pyarrow', 'Pygments', 'pyparsing', 'python-dateutil', 'pytz', 'pywin32', 'pyzmq', 'requests', 'scikit-learn', 'scipy', 'seaborn', 'six', 'sklearn', 'stack-data', 'threadpoolctl', 'torch', 'torchaudio', 'torchvision', 'tornado', 'traitlets', 'typing_extensions', 'urllib3', 'wcwidth', 'widgetsnbextension']\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "reqs = subprocess.check_output([sys.executable, '-m', 'pip', 'freeze'])\n",
    "installed_packages = [r.decode().split('==')[0] for r in reqs.split()]\n",
    "print(installed_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['functools', 'statsmodels']\n"
     ]
    }
   ],
   "source": [
    "instPks = list(set(reqPkgs) - set(installed_packages))\n",
    "print(instPks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (3.6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: statsmodels in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (0.13.5)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from statsmodels) (1.9.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from statsmodels) (1.5.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from statsmodels) (1.23.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from packaging>=21.3->statsmodels) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.25->statsmodels) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (8.0.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipywidgets) (6.17.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from ipywidgets) (4.0.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipywidgets) (8.6.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipywidgets) (5.5.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.4)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\n",
      "Requirement already satisfied: packaging in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
      "Requirement already satisfied: psutil in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.3)\n",
      "Requirement already satisfied: pickleshare in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: stack-data in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: colorama in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: decorator in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.13.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.31)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.11.2)\n",
      "Requirement already satisfied: wcwidth in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (304)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (0.12.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from seaborn) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from seaborn) (1.23.4)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from seaborn) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\stehayes\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.25->seaborn) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install statsmodels\n",
    "%pip install ipywidgets\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: p in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: click<8.0.0,>=7.1.2 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from p) (7.1.2)\n",
      "Requirement already satisfied: click-didyoumean<0.4.0,>=0.3.0 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from p) (0.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: p in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: click<8.0.0,>=7.1.2 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from p) (7.1.2)\n",
      "Requirement already satisfied: click-didyoumean<0.4.0,>=0.3.0 in c:\\source\\repos\\dublinbusweatherproject\\dublinbusenv\\lib\\site-packages (from p) (0.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "for p in instPks:\n",
    "    %pip install p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.stats as stats\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from functools import partial\n",
    "import IPython\n",
    "import ipywidgets\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import interact, interactive,fixed\n",
    "import operator\n",
    "from IPython.display import Javascript, display,HTML\n",
    "from ipywidgets import widgets, VBox\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import getpass\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ConfUtility():   \n",
    "    @staticmethod\n",
    "    def parse_yaml(input_file):\n",
    "        import yaml\n",
    "        yaml_dict = {}\n",
    "        with open (input_file,'r') as fin:\n",
    "            try:\n",
    "                yaml_dict = yaml.load(fin)\n",
    "            except Exception as ex:\n",
    "                print (ex)\n",
    "        return yaml_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def dict_to_htmllist(dc, include_list=None):\n",
    "        dc2 = {}\n",
    "        output_formatting = {'Target':'Target variable is ','CategoricalColumns':'Categorical Columns are ',\n",
    "                           'NumericalColumns':'Numerical Columns are '}\n",
    "        for each in dc.keys():\n",
    "            if not include_list or each in include_list:\n",
    "                if isinstance(dc[each],  collections.Iterable) and not isinstance(dc[each], str):\n",
    "                    dc2[each] = ', \\n'.join(val for val in dc[each])\n",
    "                else:\n",
    "                    dc2[each] = dc[each]\n",
    "        html_list = \"<ul>{}</ul>\"\n",
    "        html_list_entry = \"<li>{}</li>\"\n",
    "        output3 = ''\n",
    "\n",
    "        for each in set(include_list)|set(dc2.keys()):\n",
    "            output3 += html_list_entry.format(output_formatting[each]+dc2[each])\n",
    "        html_list = html_list.format(output3)\n",
    "        return HTML(html_list)\n",
    "    \n",
    "class InteractionAnalytics():\n",
    "    @staticmethod\n",
    "    def rank_associations(df, conf_dict, col1, col2, col3):        \n",
    "        try:\n",
    "            col2 = int(col2)\n",
    "            col3 = int(col3)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Passed Variable is Numerical\n",
    "        if (col1 in NumericalColumns):\n",
    "            fig,(ax1,ax2) = plt.subplots(1, 2)\n",
    "            if len(NumericalColumns)>1:\n",
    "                \n",
    "                # Interaction with numerical variables\n",
    "                df2 = df[NumericalColumns]\n",
    "                corrdf = df2.corr()\n",
    "                corrdf = abs(corrdf) \n",
    "                corrdf2 = corrdf[corrdf.index==col1].reset_index()[[each for each in corrdf.columns \\\n",
    "                                                      if col1 not in each]].unstack().sort_values(kind=\"quicksort\", \n",
    "                                                                                                  ascending=False).head(col2)\n",
    "                corrdf2 = corrdf2.reset_index()\n",
    "                corrdf2.columns = ['level0','level1','rsq']\n",
    "                corrdf2.set_index('level0', inplace=True)\n",
    "                corrdf2[['rsq']].plot(kind='bar', ax=ax1)\n",
    "                ax1.legend().set_visible(False)\n",
    "                ax1.set_xlabel('Absolute Correlation')\n",
    "                ax1.set_title('Top {} Associated Numeric Variables'.format(str(col2)))\n",
    "                # Interaction with categorical variables\n",
    "                etasquared_dict = {}\n",
    "            if len(CategoricalColumns) >= 1:\n",
    "                for each in CategoricalColumns:\n",
    "                    mod = ols('{} ~ C({})'.format(col1, each),data=df[[col1,each]],missing='drop').fit()\n",
    "                    aov_table = sm.stats.anova_lm(mod, typ=1)\n",
    "                    esq_sm = aov_table['sum_sq'][0]/(aov_table['sum_sq'][0]+aov_table['sum_sq'][1])\n",
    "                    etasquared_dict[each] = esq_sm\n",
    "\n",
    "                topk_esq = pd.DataFrame.from_dict(etasquared_dict, orient='index').unstack().sort_values(\\\n",
    "                    kind = 'quicksort', ascending=False).head(col3).reset_index().set_index('level_1')\n",
    "                topk_esq.columns = ['level_0', 'EtaSquared']\n",
    "                topk_esq[['EtaSquared']].plot(kind='bar',ax=ax2)\n",
    "                ax2.legend().set_visible(False)\n",
    "                ax2.set_xlabel('Eta-squared values')\n",
    "                ax2.set_title('Top {}  Associated Categoric Variables'.format(str(col2)))\n",
    "        # Passed Variable is Categorical\n",
    "        else:\n",
    "            #Interaction with numerical variables\n",
    "            fig,(ax1,ax2) = plt.subplots(1,2)\n",
    "            if len(NumericalColumns) >= 1:\n",
    "                etasquared_dict = {}\n",
    "                for each in NumericalColumns:\n",
    "                    mod = ols('{} ~ C({})'.format(each, col1), data = df[[col1,each]]).fit()\n",
    "                    aov_table = sm.stats.anova_lm(mod, typ=1)\n",
    "                    esq_sm = aov_table['sum_sq'][0]/(aov_table['sum_sq'][0]+aov_table['sum_sq'][1])\n",
    "                    etasquared_dict[each] = esq_sm\n",
    "\n",
    "                topk_esq = pd.DataFrame.from_dict(etasquared_dict, orient='index').unstack().sort_values(\\\n",
    "                    kind = 'quicksort', ascending=False).head(col2).reset_index().set_index('level_1')\n",
    "                topk_esq.columns = ['level_0','EtaSquared']\n",
    "                topk_esq[['EtaSquared']].plot(kind='bar',ax=ax1)\n",
    "                ax1.legend().set_visible(False)\n",
    "                ax1.set_xlabel('Eta-squared values')\n",
    "                ax1.set_title('Top {} Associated Numeric Variables'.format(str(col2)))\n",
    "\n",
    "            # Interaction with categorical variables\n",
    "            cramer_dict = {}\n",
    "            if len(CategoricalColumns)>1:\n",
    "                for each in CategoricalColumns:\n",
    "                    if each !=col1:\n",
    "                        tbl = pd.crosstab(df[col1], df[each])\n",
    "                        chisq = stats.chi2_contingency(tbl, correction=False)[0]\n",
    "                        try:\n",
    "                            cramer = np.sqrt(chisq/sum(tbl))\n",
    "                        except:\n",
    "                            cramer = np.sqrt(chisq/tbl.as_matrix().sum())\n",
    "                            pass\n",
    "                        cramer_dict[each] = cramer\n",
    "\n",
    "                topk_cramer = pd.DataFrame.from_dict(cramer_dict, orient='index').unstack().sort_values(\\\n",
    "                    kind = 'quicksort', ascending=False).head(col3).reset_index().set_index('level_1')\n",
    "                topk_cramer.columns = ['level_0','CramersV']\n",
    "                topk_cramer[['CramersV']].plot(kind='bar',ax=ax2)\n",
    "                ax2.legend().set_visible(False)\n",
    "                ax2.set_xlabel(\"Cramer's V\")\n",
    "                ax2.set_title('Top {} Associated Categoric Variables'.format(str(col2)))\n",
    "        \n",
    "    @staticmethod\n",
    "    def NoLabels(x):\n",
    "        return ''\n",
    "    \n",
    "    @staticmethod\n",
    "    def categorical_relations(df, col1, col2):\n",
    "        if col1 != col2:\n",
    "            df2 = df[(df[col1].isin(df[col1].value_counts().head(10).index.tolist()))&(df[col2].isin(df[col2].value_counts().head(10).index.tolist())) ]\n",
    "            df3 = pd.crosstab(df2[col1], df2[col2])\n",
    "            df3 = df3+1e-8\n",
    "        else:\n",
    "            df3 = pd.DataFrame(df[col1].value_counts())[:10]\n",
    "        fig,ax = plt.subplots()\n",
    "        fig,rects = mosaic(df3.unstack(),ax=ax, statistic=False, labelizer=InteractionAnalytics.NoLabels, label_rotation=30)\n",
    "        ax.set_ylabel(col1)\n",
    "        ax.set_xlabel(col2)\n",
    "        ax.set_title('{} vs {}'.format(col1, col2) )\n",
    "    \n",
    "    @staticmethod\n",
    "    def numerical_relations(df, col1, col2):\n",
    "        from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "        x = df[col2]\n",
    "        y = df[col1]\n",
    "        f, ax = plt.subplots(1)\n",
    "\n",
    "        # lowess\n",
    "        ax.scatter(x, y, c='g', s=6)\n",
    "        lowess_results = lowess(y, x)#[:,1]\n",
    "        xs = lowess_results[:, 0]\n",
    "        ys = lowess_results[:, 1]\n",
    "        ax.plot(xs,ys,'red',linewidth=1)\n",
    "\n",
    "        #ols\n",
    "        fit = np.polyfit(x, y, 1)\n",
    "        fit1d = np.poly1d(fit)\n",
    "        ax.plot(x, fit1d(x), '--b')\n",
    "        ax.set_xlabel(col2)\n",
    "        ax.set_ylabel(col1)\n",
    "        corr = round(scipy.stats.pearsonr(x, y)[0], 6)\n",
    "        ax.set_title('{} vs {}, Correlation {}'.format(col1, col2, corr))\n",
    "    \n",
    "    @staticmethod\n",
    "    def numerical_correlation(df, conf_dict, col1):\n",
    "        from matplotlib.pyplot import quiver, colorbar, clim,  matshow\n",
    "        df2 = df[NumericalColumns].corr(method=col1)\n",
    "        col_names = list(df[NumericalColumns].columns)\n",
    "        fig,ax = plt.subplots(1, 1)\n",
    "        m = ax.matshow(df2, cmap=matplotlib.pyplot.cm.coolwarm)\n",
    "        ax.grid(b=False)\n",
    "        fig.colorbar(m)\n",
    "        ax.set_xticklabels([' '] + col_names) \n",
    "        ax.set_yticklabels([' '] + col_names)\n",
    "\n",
    "    @staticmethod\n",
    "    def numerical_pca(df, conf_dict, col1, col2, col3):\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        num_numeric = len(NumericalColumns)\n",
    "        num_pca = num_numeric\n",
    "        xticklabels = ['']\n",
    "        for i in range(1,num_pca+1):\n",
    "            xticklabels+=['Comp'+str(i)]\n",
    "            xticklabels+=['']\n",
    "        df2 = df[NumericalColumns]\n",
    "        X = StandardScaler().fit_transform(df2.values)\n",
    "        pca = PCA(n_components=num_pca)\n",
    "        pca.fit(X)\n",
    "        fig, (ax1,ax2) = plt.subplots(1, 2)\n",
    "        ax1.bar(np.arange(1,(num_numeric+1),1),pca.explained_variance_ratio_ )\n",
    "        ax1.set_ylabel('% Variance Explained')\n",
    "        ax1.set_xticklabels(xticklabels)\n",
    "        x_pca_index = int(col2) - 1\n",
    "        y_pca_index = int(col3) - 1\n",
    "        Y_pca = pd.DataFrame(pca.fit_transform(X))\n",
    "        Y_pca_labels = []\n",
    "        for i in range(1,num_pca+1):\n",
    "            Y_pca_labels.append('PC'+str(i))\n",
    "        Y_pca.columns = Y_pca_labels       \n",
    "        Y_pca[col1] = df[col1]\n",
    "        colors_dict = {}\n",
    "        colors_list = ['r', 'y', 'c', 'y', 'k']\n",
    "        j = 0\n",
    "        for i in np.unique(df[col1]):\n",
    "            colors_dict[i] = colors_list[j]\n",
    "            j += 1\n",
    "            if j == len(colors_list):\n",
    "                j = 0\n",
    "        colordf = pd.DataFrame.from_dict(colors_dict, orient='index').reset_index()\n",
    "        colordf.columns = [col1, 'color']\n",
    "        merged_df = pd.merge(colordf,Y_pca)\n",
    "        grouped_df = merged_df.groupby(col1)\n",
    "        for name, group in grouped_df:\n",
    "            ax2.scatter(\n",
    "               group[Y_pca.columns[x_pca_index]], group[Y_pca.columns[y_pca_index]],label=name,  \n",
    "               c=group['color'],                            \n",
    "               marker='o',                                \n",
    "               s=6)                                       \n",
    "        ax2.set_xlabel(Y_pca.columns[x_pca_index])\n",
    "        ax2.set_ylabel(Y_pca.columns[y_pca_index])\n",
    "        ax2.legend(title=col1, fontsize=14)\n",
    "                \n",
    "    @staticmethod\n",
    "    def nc_relation(df, conf_dict, col1, col2, col3=None):\n",
    "        fig,ax = plt.subplots()\n",
    "        f = df[[col1,col2]].boxplot(by=col2, ax=ax)\n",
    "        mod = ols('{} ~ {}'.format(col1, col2), data=df[[col1, col2]]).fit()\n",
    "        aov_table = sm.stats.anova_lm(mod, typ=1)\n",
    "        p_val = round(aov_table['PR(>F)'][0], 6)\n",
    "        status = 'Passed'\n",
    "        color = 'blue'\n",
    "        if p_val < 0.05:\n",
    "            status = 'Rejected'\n",
    "            color = 'red'\n",
    "        fig.suptitle('ho {} (p_value = {})'.format( status, p_val), color=color, fontsize=10)\n",
    "    \n",
    "    @staticmethod\n",
    "    def pca_3d(df, conf_dict, col1, col2,  col3=None):\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        df2 = df[NumericalColumns]\n",
    "        X = StandardScaler().fit_transform(df2.values)\n",
    "        pca = PCA(n_components=4)\n",
    "        pca.fit(X)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "        ax.view_init(elev=10, azim=int(col2))              \n",
    "        Y_pca = pd.DataFrame(pca.fit_transform(X))\n",
    "        Y_pca.columns = ['PC1','PC2','PC3','PC4']\n",
    "        Y_pca[col1] = df[col1]\n",
    "        colors_dict = {}\n",
    "        colors_list = ['r', 'y', 'c', 'y', 'k']\n",
    "        j = 0\n",
    "        for i in np.unique(df[col1]):\n",
    "            colors_dict[i] = colors_list[j]\n",
    "            j += 1\n",
    "            if j == len(colors_list):\n",
    "                j = 0\n",
    "        colordf = pd.DataFrame.from_dict(colors_dict, orient='index').reset_index()\n",
    "        colordf.columns = [col1,'color']\n",
    "        merged_df = pd.merge(colordf,Y_pca)\n",
    "        grouped_df = merged_df.groupby(col1)\n",
    "        for name, group in grouped_df:\n",
    "            ax.scatter(\n",
    "               group['PC1'], group['PC2'], group['PC3'], label=name,  \n",
    "               c = group['color'],                            \n",
    "               marker = 'o',                                \n",
    "               s=6)                                      \n",
    "        ax.set_xlabel('PC1', labelpad=18)\n",
    "        ax.set_ylabel('PC2', labelpad=18)\n",
    "        ax.set_zlabel('PC3', labelpad=18)\n",
    "        ax.legend(title=col1, fontsize=10)\n",
    "\n",
    "    @staticmethod\n",
    "    def pca_3d_new(df, conf_dict, col1, col2, col3, col4, col5):\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        df2 = df[NumericalColumns]\n",
    "        X = StandardScaler().fit_transform(df2.values)\n",
    "        num_numeric = len(NumericalColumns)\n",
    "        pca = PCA(n_components=num_numeric)\n",
    "        pca.fit(X)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "        ax.view_init(elev=10, azim=int(col5))                 \n",
    "        Y_pca = pd.DataFrame(pca.fit_transform(X))\n",
    "        Y_pca_names = []\n",
    "        for i in range(1, num_numeric+1):\n",
    "            Y_pca_names.append('PC'+str(i))\n",
    "        Y_pca.columns = Y_pca_names\n",
    "        Y_pca[col1] = df[col1]\n",
    "        colors_dict = {}\n",
    "        colors_list = ['r', 'y', 'c', 'y', 'k']\n",
    "        j = 0\n",
    "        for i in np.unique(df[col1]):\n",
    "            colors_dict[i] = colors_list[j]\n",
    "            j += 1\n",
    "            if j == len(colors_list):\n",
    "                j = 0\n",
    "        colordf = pd.DataFrame.from_dict(colors_dict, orient='index').reset_index()\n",
    "        colordf.columns = [col1,'color']\n",
    "        merged_df = pd.merge(colordf,Y_pca)\n",
    "        grouped_df = merged_df.groupby(col1)\n",
    "        for name, group in grouped_df:\n",
    "            ax.scatter(\n",
    "               group[Y_pca_names[int(col2)-1]], group[Y_pca_names[int(col3)-1]], group[Y_pca_names[int(col4)-1]], label=name,  \n",
    "               c = group['color'],                            \n",
    "               marker = 'o',                                \n",
    "               s=6)\n",
    "        ax.set_xlabel(Y_pca_names[int(col2)-1], labelpad=18)\n",
    "        ax.set_ylabel(Y_pca_names[int(col3)-1], labelpad=18)\n",
    "        ax.set_zlabel(Y_pca_names[int(col4)-1], labelpad=18)\n",
    "        ax.legend(title=col1, fontsize=10)\n",
    "        \n",
    "    @staticmethod\n",
    "    def nnc_relation(df, conf_dict, col1, col2, col3):\n",
    "        import itertools\n",
    "        markers = ['x', 'o', '^']\n",
    "        color = itertools.cycle(['r', 'y', 'c', 'y', 'k']) \n",
    "        groups = df[[col1, col2, col3]].groupby(col3)\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.margins(0.05) \n",
    "\n",
    "        for (name, group), marker in zip(groups, itertools.cycle(markers)):\n",
    "            ax.plot(group[col1], group[col2], marker='o', linestyle='', ms=4, label=name)\n",
    "        ax.set_xlabel(col1)\n",
    "        ax.set_ylabel(col2)\n",
    "        ax.legend(numpoints=1, loc='best', title=col3)\n",
    "        \n",
    "class TargetAnalytics():\n",
    "    ReportedVariables = []\n",
    "    @staticmethod\n",
    "    def custom_barplot(df, col1=''):\n",
    "        f, (ax0,ax1) = plt.subplots(1, 2)\n",
    "        df[col1].value_counts().plot(ax=ax0, kind='bar')\n",
    "        ax0.set_title('Bar Plot of {}'.format(col1))\n",
    "        df[col1].value_counts().plot(ax=ax1, kind='pie')\n",
    "        ax1.set_title('Pie Chart of {}'.format(col1))\n",
    "\n",
    "class NumericAnalytics():\n",
    "    @staticmethod\n",
    "    def shapiro_test(x):\n",
    "        p_val = round(stats.shapiro(x)[1],6)\n",
    "        status = 'passed'\n",
    "        color = 'blue'\n",
    "        if p_val < 0.05:\n",
    "            status = 'failed'\n",
    "            color = 'red'\n",
    "        return status, color, p_val\n",
    "\n",
    "    @staticmethod\n",
    "    def custom_barplot(df, col1=''):\n",
    "        fig, axes = plt.subplots(2,2)\n",
    "        axes = axes.reshape(-1)\n",
    "        df[col1].plot(ax=axes[0], kind='hist')\n",
    "        axes[0].set_title('Histogram of {}'.format(col1))\n",
    "        df[col1].plot(ax=axes[1], kind='kde')\n",
    "        axes[1].set_title('Density Plot of {}'.format(col1))\n",
    "        ax3 = plt.subplot(223)\n",
    "        stats.probplot(df[col1], plot=plt)\n",
    "        axes[2].set_title('QQ Plot of {}'.format(col1))\n",
    "        df[col1].plot(ax=axes[3], kind='box')\n",
    "        axes[3].set_title('Box Plot of {}'.format(col1))\n",
    "        status, color, p_val = NumericAnalytics.shapiro_test(df[col1])\n",
    "        fig.suptitle('Normality test for {} {} (p_value = {})'.format(col1, status, round(p_val, 6)), color=color, fontsize=12)\n",
    "    \n",
    "class CategoricAnalytics():\n",
    "    @staticmethod\n",
    "    def custom_barplot(df, col1=''):\n",
    "        f, (ax0,ax1) = plt.subplots(1,2)\n",
    "        df[col1].value_counts().nlargest(10).plot(ax=ax0, kind='bar')\n",
    "        ax0.set_xlabel(col1)\n",
    "        ax0.set_title('Bar chart of {}'.format(col1))\n",
    "        df[col1].value_counts().nlargest(10).plot(ax=ax1, kind='pie')\n",
    "        ax1.set_title('Pie chart of {}'.format(col1))\n",
    " \n",
    "%matplotlib inline\n",
    "font={'family':'normal','weight':'normal','size':8}\n",
    "matplotlib.rc('font',**font)\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 5.0)\n",
    "matplotlib.rc('xtick', labelsize=9) \n",
    "matplotlib.rc('ytick', labelsize=9)\n",
    "matplotlib.rc('axes', labelsize=10)\n",
    "matplotlib.rc('axes', titlesize=10)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"read and summarize\"></a> Read and Summarize the Data\n",
    "\n",
    "### Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>LineID</th>\n",
       "      <th>Direction</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>VehicleJourneyID</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Congestion</th>\n",
       "      <th>LonWGS84</th>\n",
       "      <th>LatWGS84</th>\n",
       "      <th>Delay</th>\n",
       "      <th>BlockID</th>\n",
       "      <th>VehicleID</th>\n",
       "      <th>AtStop</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Time</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1356998405000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>3883</td>\n",
       "      <td>RD</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.233417</td>\n",
       "      <td>53.342232</td>\n",
       "      <td>0</td>\n",
       "      <td>27017</td>\n",
       "      <td>33521</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01 00:00:05</td>\n",
       "      <td>00:00:05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1356998407000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>2226</td>\n",
       "      <td>HN</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.278250</td>\n",
       "      <td>53.416683</td>\n",
       "      <td>0</td>\n",
       "      <td>40206</td>\n",
       "      <td>33142</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01 00:00:07</td>\n",
       "      <td>00:00:07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1356998407000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>6106</td>\n",
       "      <td>D1</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.231633</td>\n",
       "      <td>53.317768</td>\n",
       "      <td>0</td>\n",
       "      <td>7019</td>\n",
       "      <td>43004</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01 00:00:07</td>\n",
       "      <td>00:00:07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1356998411000000</td>\n",
       "      <td>747.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>3531</td>\n",
       "      <td>SL</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.254617</td>\n",
       "      <td>53.355484</td>\n",
       "      <td>-454</td>\n",
       "      <td>747007</td>\n",
       "      <td>40039</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01 00:00:11</td>\n",
       "      <td>00:00:11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1356998411000000</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1830</td>\n",
       "      <td>RD</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.233183</td>\n",
       "      <td>53.342201</td>\n",
       "      <td>0</td>\n",
       "      <td>56001</td>\n",
       "      <td>33488</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01 00:00:11</td>\n",
       "      <td>00:00:11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Timestamp  LineID  Direction   TimeFrame  VehicleJourneyID Operator  \\\n",
       "0  1356998405000000    27.0          0  2012-12-31              3883       RD   \n",
       "1  1356998407000000    40.0          0  2012-12-31              2226       HN   \n",
       "2  1356998407000000     7.0          0  2012-12-31              6106       D1   \n",
       "3  1356998411000000   747.0          0  2012-12-31              3531       SL   \n",
       "4  1356998411000000    56.0          0  2012-12-31              1830       RD   \n",
       "\n",
       "   Congestion  LonWGS84   LatWGS84  Delay  BlockID  VehicleID  AtStop  \\\n",
       "0           0 -6.233417  53.342232      0    27017      33521       0   \n",
       "1           0 -6.278250  53.416683      0    40206      33142       0   \n",
       "2           0 -6.231633  53.317768      0     7019      43004       1   \n",
       "3           0 -6.254617  53.355484   -454   747007      40039       0   \n",
       "4           0 -6.233183  53.342201      0    56001      33488       0   \n",
       "\n",
       "             datetime      Time  Day  Hour  Minute  \n",
       "0 2013-01-01 00:00:05  00:00:05    1     0       0  \n",
       "1 2013-01-01 00:00:07  00:00:07    1     0       0  \n",
       "2 2013-01-01 00:00:07  00:00:07    1     0       0  \n",
       "3 2013-01-01 00:00:11  00:00:11    1     0       0  \n",
       "4 2013-01-01 00:00:11  00:00:11    1     0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = './Data/Bus/Gz/siri.20130101.csv.gz'\n",
    "df = pd.read_csv(data_file, compression='gzip')\n",
    "df.columns = ['Timestamp', 'Line ID', 'Direction', 'Journey Pattern ID', 'Time Frame', 'Vehicle Journey ID', 'Operator', 'Congestion', 'Lon WGS84', 'Lat WGS84', 'Delay', 'Block ID', 'Vehicle ID', 'Stop ID', 'At Stop']\n",
    "bdf = pd.read_parquet('./Data/Bus/CleanedBusData.parquet')\n",
    "bdf['datetime'] = pd.to_datetime(bdf['datetime'])\n",
    "\n",
    "df = pd.read_csv('./Data/MetEirrean/hly175.csv', delimiter=',', header=0,  parse_dates=True, low_memory=True, skiprows=14, na_values='NAN')\n",
    "# Deal with the timestamp and make it human readable\n",
    "df['datetime'] = pd.to_datetime(df['date'])\n",
    "df['Year'] = df['datetime'].dt.year\n",
    "df['Month'] = df['datetime'].dt.month\n",
    "df['Day'] = df['datetime'].dt.day\n",
    "df['Time'] = df['datetime'].dt.time\n",
    "df['Hour'] = df['datetime'].dt.hour\n",
    "df['Minute'] = df['datetime'].dt.minute\n",
    "df = df[df['Year'] == 2013]\n",
    "df = df[df['Month'] == 1]\n",
    "df = df.astype({\"rain\": float})\n",
    "df = df.astype({\"temp\": float})\n",
    "df = df.astype({\"wetb\": float})\n",
    "df = df.astype({\"dewpt\": float})\n",
    "df = df.astype({\"vappr\": float})\n",
    "df = df.astype({\"rhum\": float})\n",
    "df = df.astype({\"msl\": float})\n",
    "\n",
    "bdf.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Columns and column types -- correct/modify as necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp                    int64\n",
       "LineID                     float64\n",
       "Direction                    int64\n",
       "TimeFrame                   object\n",
       "VehicleJourneyID             int64\n",
       "Operator                    object\n",
       "Congestion                   int64\n",
       "LonWGS84                   float64\n",
       "LatWGS84                   float64\n",
       "Delay                        int64\n",
       "BlockID                      int64\n",
       "VehicleID                    int64\n",
       "AtStop                       int64\n",
       "datetime            datetime64[ns]\n",
       "Time                        object\n",
       "Day                          int64\n",
       "Hour                         int64\n",
       "Minute                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>LineID</th>\n",
       "      <th>Direction</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>VehicleJourneyID</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Congestion</th>\n",
       "      <th>LonWGS84</th>\n",
       "      <th>LatWGS84</th>\n",
       "      <th>Delay</th>\n",
       "      <th>...</th>\n",
       "      <th>ind.1</th>\n",
       "      <th>temp</th>\n",
       "      <th>ind.2</th>\n",
       "      <th>wetb</th>\n",
       "      <th>dewpt</th>\n",
       "      <th>vappr</th>\n",
       "      <th>rhum</th>\n",
       "      <th>msl</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1357038000000000</td>\n",
       "      <td>332.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>13304</td>\n",
       "      <td>HN</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.116812</td>\n",
       "      <td>53.499493</td>\n",
       "      <td>-20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1357038000000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>15580</td>\n",
       "      <td>RD</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.212467</td>\n",
       "      <td>53.324749</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1357038000000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>13445</td>\n",
       "      <td>CD</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.451066</td>\n",
       "      <td>53.347698</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1357038000000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>14732</td>\n",
       "      <td>PO</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.394768</td>\n",
       "      <td>53.393051</td>\n",
       "      <td>-333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1357038000000000</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>15099</td>\n",
       "      <td>CD</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.373067</td>\n",
       "      <td>53.286098</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Timestamp  LineID  Direction   TimeFrame  VehicleJourneyID Operator  \\\n",
       "0  1357038000000000   332.0          0  2013-01-01             13304       HN   \n",
       "1  1357038000000000     1.0          0  2013-01-01             15580       RD   \n",
       "2  1357038000000000    25.0          0  2013-01-01             13445       CD   \n",
       "3  1357038000000000    39.0          0  2013-01-01             14732       PO   \n",
       "4  1357038000000000    76.0          0  2013-01-01             15099       CD   \n",
       "\n",
       "   Congestion  LonWGS84   LatWGS84  Delay  ...  ind.1  temp  ind.2 wetb dewpt  \\\n",
       "0           0 -6.116812  53.499493    -20  ...      0   3.6      0  2.7   1.2   \n",
       "1           0 -6.212467  53.324749      0  ...      0   3.6      0  2.7   1.2   \n",
       "2           0 -6.451066  53.347698      0  ...      0   3.6      0  2.7   1.2   \n",
       "3           0 -6.394768  53.393051   -333  ...      0   3.6      0  2.7   1.2   \n",
       "4           0 -6.373067  53.286098      0  ...      0   3.6      0  2.7   1.2   \n",
       "\n",
       "   vappr  rhum     msl  Year  Month  \n",
       "0    6.7  84.0  1009.0  2013      1  \n",
       "1    6.7  84.0  1009.0  2013      1  \n",
       "2    6.7  84.0  1009.0  2013      1  \n",
       "3    6.7  84.0  1009.0  2013      1  \n",
       "4    6.7  84.0  1009.0  2013      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join weather and bus \n",
    "mdf = pd.merge(bdf, df)\n",
    "mdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 12, 17,  8, 10, 16, 21, 22, 23, 15, 18, 19, 20, 14,  0, 13,  7,\n",
       "        9], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf['Hour'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove the space in column names\n",
    "df.columns = [x.strip().replace(' ', '') for x in df.columns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the list of categorical columns if it was not there in the yaml file\n",
    "CategoricalColumns = list(set(list(df.select_dtypes(exclude=[np.number]).columns)))\n",
    "\n",
    "NumericalColumns = list(set(list(df.select_dtypes([np.number]).columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CategoricalColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NumericalColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclude columns that we do not need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnsToExclude = ['JourneyPatternID', 'StopID']\n",
    "CategoricalColumns = list(set(CategoricalColumns) - set(ColumnsToExclude))\n",
    "NumericalColumns = list(set(NumericalColumns)-set(ColumnsToExclude))\n",
    "\n",
    "Target = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(ColumnsToExclude, axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the dimensions of the data (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The data has {} Rows and {} columns'.format(df.shape[0],df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the dimensions of the data (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ','.join(each for each in list(df.columns))\n",
    "print(\"The column names are:\" + col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The types of columns are:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"descriptive statistics\"></a>Extract Descriptive Statistics of Each Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_missing(x):\n",
    "    return len(x.index)-x.count()\n",
    "\n",
    "def num_unique(x):\n",
    "    return len(np.unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_df = pd.DataFrame(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.describe().T\n",
    "missing_df = pd.DataFrame(df.apply(num_missing, axis=0)) \n",
    "missing_df.columns = ['missing']\n",
    "unq_df = pd.DataFrame(df.apply(num_unique, axis=0))\n",
    "unq_df.columns = ['unique']\n",
    "types_df = pd.DataFrame(df.dtypes)\n",
    "types_df.columns = ['DataType']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the descriptive statistics of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_df = temp_df.join(missing_df).join(unq_df).join(types_df)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the descriptive statistics of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(types_df.index)\n",
    "num_cols = len(col_names)\n",
    "index = range(num_cols)\n",
    "cat_index = []\n",
    "for i in index:\n",
    "    if col_names[i] in CategoricalColumns:\n",
    "        cat_index.append(i)\n",
    "summary_df_cat = missing_df.join(unq_df).join(types_df.iloc[cat_index], how='inner') #Only summarize categorical columns\n",
    "summary_df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"individual variables\"></a>Explore Individual Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Target in CategoricalColumns:\n",
    "    w1_value = ''\n",
    "    w1 = None  \n",
    "    w1 = widgets.Dropdown(\n",
    "        options=[Target],\n",
    "        value=Target,\n",
    "        description='Target Variable:',\n",
    "    )\n",
    "    i = interactive(TargetAnalytics.custom_barplot, df=fixed(df), col1=w1)\n",
    "    hbox = widgets.HBox(i.children[:1])\n",
    "    display(hbox)\n",
    "    hbox.on_displayed(TargetAnalytics.custom_barplot(df=df, col1=w1.value))\n",
    "else:\n",
    "    w1_value = ''\n",
    "    w1 = None\n",
    "    w1 = widgets.Dropdown(\n",
    "            options=[Target],\n",
    "            value=Target,\n",
    "            description='Target Variable:',\n",
    "        )\n",
    "    i = interactive(NumericAnalytics.custom_barplot, df=fixed(df), col1=w1)\n",
    "    hbox = widgets.HBox(i.children)\n",
    "    display(hbox)\n",
    "    hbox.on_displayed(NumericAnalytics.custom_barplot(df=df, col1=w1.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore individual numeric variables and test for normality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CategoricalColumns = list(set(['LineID', 'Direction', 'TimeFrame', 'VehicleJourneyID', 'Operator', 'Congestion',  'Delay', 'BlockID', 'VehicleID', 'StopID', 'AtStop']))\n",
    "NumericalColumns = list(set(list(df.select_dtypes([np.number]).columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_value = ''\n",
    "w1 = None\n",
    "w1 = widgets.Dropdown(\n",
    "        options=NumericalColumns,\n",
    "        value=NumericalColumns[0],\n",
    "        description='Numeric Variable:',\n",
    "    )\n",
    "\n",
    "i = interactive(NumericAnalytics.custom_barplot, df=fixed(df), col1=w1)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(NumericAnalytics.custom_barplot(df=df, col1=w1.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore individual categorical variables (sorted by frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_value = ''\n",
    "w1 = None\n",
    "\n",
    "w1 = widgets.Dropdown(\n",
    "    options = CategoricalColumns,\n",
    "    value = CategoricalColumns[0],\n",
    "    description = 'Categorical Variable:',\n",
    ")\n",
    "\n",
    "\n",
    "i = interactive(CategoricAnalytics.custom_barplot, df=fixed(df), col1=w1)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(CategoricAnalytics.custom_barplot(df=df, col1=w1.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"multiple variables\"></a>Explore Interactions Between Variables\n",
    "### <a name=\"rank variables\"></a>Rank variables based on linear relationships with reference variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = [Target] + NumericalColumns + CategoricalColumns\n",
    "cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "w1 = widgets.Dropdown(    \n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Ref Var:'\n",
    ")\n",
    "w2 = ipywidgets.Text(value=\"5\", description='Top Num Vars:')\n",
    "w3 = ipywidgets.Text(value=\"5\", description='Top Cat Vars:')\n",
    "i = interactive(InteractionAnalytics.rank_associations, df=fixed(df),conf_dict=fixed(cols_list), col1=w1, col2=w2, col3=w3)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.rank_associations(df=df, conf_dict=cols_list, col1=w1.value, col2=w2.value, col3=w3.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"two categorical\"></a>Explore interactions between categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = None, None\n",
    "\n",
    "if Target in CategoricalColumns:\n",
    "    cols_list = [Target] + CategoricalColumns \n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "else:\n",
    "    cols_list = CategoricalColumns\n",
    "    \n",
    "w1 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Categorical Var 1:'\n",
    ")\n",
    "w2 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[1],\n",
    "    description='Categorical Var 2:'\n",
    ")\n",
    "\n",
    "i = interactive(InteractionAnalytics.categorical_relations, df=fixed(df), col1=w1, col2=w2)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.categorical_relations(df=df, col1=w1.value, col2=w2.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"two numerical\"></a>Explore interactions between numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = None, None\n",
    "\n",
    "if Target in NumericalColumns:\n",
    "    cols_list = [Target] + NumericalColumns \n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "else:\n",
    "    cols_list = NumericalColumns\n",
    "w1 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Numerical Var 1:'\n",
    ")\n",
    "w2 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[1],\n",
    "    description='Numerical Var 2:'\n",
    ")\n",
    "i = interactive(InteractionAnalytics.numerical_relations, df=fixed(df), col1=w1, col2=w2)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.numerical_relations(df, col1=w1.value, col2=w2.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore correlation matrix between numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = None\n",
    "w1 = widgets.Dropdown(\n",
    "    options=['pearson','kendall','spearman'],\n",
    "    value='pearson',\n",
    "    description='Correlation Method:'\n",
    ")\n",
    "i = interactive(InteractionAnalytics.numerical_correlation, df=fixed(df), conf_dict=fixed(cols_list), col1=w1)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.numerical_correlation(df, conf_dict=cols_list, col1=w1.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"numerical and categorical\"></a>Explore interactions between numerical and categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = None, None\n",
    "\n",
    "if Target in NumericalColumns:\n",
    "    cols_list = [Target] + NumericalColumns #Make target the default reference variable\n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) #remove variables that might be duplicates with target\n",
    "else:\n",
    "    cols_list = NumericalColumns\n",
    "    \n",
    "w1 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Numerical Variable:'\n",
    ")\n",
    "\n",
    "if Target in CategoricalColumns:\n",
    "    cols_list = [Target] + CategoricalColumns #Make target the default reference variable\n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) #remove variables that might be duplicates with target\n",
    "else:\n",
    "    cols_list = CategoricalColumns\n",
    "    \n",
    "w2 = widgets.Dropdown(\n",
    "    options=cols_list,\n",
    "    value=cols_list[0],\n",
    "    description='Categorical Variable:'\n",
    ")\n",
    "i = interactive(InteractionAnalytics.nc_relation, df=fixed(df),conf_dict=fixed(cols_list), col1=w1, col2=w2, col3=fixed(w3))\n",
    "hbox = widgets.HBox(i.children)\n",
    "display( hbox )\n",
    "hbox.on_displayed(InteractionAnalytics.nc_relation(df, cols_list, col1=w1.value, col2=w2.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"two numerical and categorical\"></a>Explore interactions between two numerical variables and a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2, w3 = None, None, None\n",
    "\n",
    "if Target in NumericalColumns:\n",
    "    cols_list = [Target] + NumericalColumns \n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "else:\n",
    "    cols_list = NumericalColumns\n",
    "    \n",
    "w1 = widgets.Dropdown(\n",
    "    options = cols_list,\n",
    "    value = cols_list[0],\n",
    "    description = 'Numerical Var 1:'\n",
    ")\n",
    "w2 = widgets.Dropdown(\n",
    "    options = cols_list,\n",
    "    value = cols_list[1],\n",
    "    description = 'Numerical Var 2:'\n",
    ")\n",
    "\n",
    "if Target in CategoricalColumns:\n",
    "    cols_list = [Target] + CategoricalColumns\n",
    "    cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "else:\n",
    "    cols_list = CategoricalColumns\n",
    "    \n",
    "w3 = widgets.Dropdown(\n",
    "    options = cols_list,\n",
    "    value = cols_list[0],\n",
    "    description = 'Legend Cat Var:'\n",
    ")\n",
    "i = interactive(InteractionAnalytics.nnc_relation, df=fixed(df),conf_dict=fixed(cols_list), col1=w1, col2=w2, col3=w3)\n",
    "hbox = widgets.HBox(i.children)\n",
    "display(hbox)\n",
    "hbox.on_displayed(InteractionAnalytics.nnc_relation(df, cols_list, col1=w1.value,col2=w2.value, col3=w3.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"pca\"></a>Visualize numerical data by projecting to principal component spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project data to 2-D principal component space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_numeric = len(NumericalColumns)\n",
    "if  num_numeric > 3:\n",
    "    \n",
    "    w1, w2, w3 = None, None, None\n",
    "    if Target in CategoricalColumns:\n",
    "        cols_list = [Target] + CategoricalColumns \n",
    "        cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "    else:\n",
    "        cols_list = CategoricalColumns\n",
    "    w1 = widgets.Dropdown(\n",
    "        options = cols_list,\n",
    "        value = cols_list[0],\n",
    "        description = 'Legend Variable:',\n",
    "        width = 10\n",
    "    )\n",
    "    w2 = widgets.Dropdown(\n",
    "        options = [str(x) for x in np.arange(1,num_numeric+1)],\n",
    "        value = '1',\n",
    "        width = 1,\n",
    "        description='PC at X-Axis:'\n",
    "    )\n",
    "    w3 = widgets.Dropdown(\n",
    "        options = [str(x) for x in np.arange(1,num_numeric+1)],\n",
    "        value = '2',\n",
    "        description = 'PC at Y-Axis:'\n",
    "    )\n",
    "    i = interactive(InteractionAnalytics.numerical_pca, df=fixed(df),conf_dict=fixed(cols_list), col1=w1, col2=w2, col3=w3)\n",
    "    hbox = widgets.HBox(i.children[:3])\n",
    "    display(hbox)\n",
    "    hbox.on_displayed(InteractionAnalytics.numerical_pca(df, conf_dict=cols_list, col1=w1.value, col2=w2.value, col3=w3.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project data to 3-D principal component space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(NumericalColumns) > 3:\n",
    "    if Target in CategoricalColumns:\n",
    "        cols_list = [Target] + CategoricalColumns \n",
    "        cols_list = list(OrderedDict.fromkeys(cols_list)) \n",
    "    else:\n",
    "        cols_list = CategoricalColumns\n",
    "    w1, w2 = None, None\n",
    "    w1 = widgets.Dropdown(\n",
    "        options=cols_list,\n",
    "        value=cols_list[0],\n",
    "        description='Legend Variable:'\n",
    "    )\n",
    "    w2 = ipywidgets.IntSlider(min=-180, max=180, step=5, value=30, description='Angle')\n",
    "    i = interactive(InteractionAnalytics.pca_3d, df=fixed(df), conf_dict=fixed(cols_list),col1=w1, col2=w2, col3=fixed(w3))\n",
    "    hbox=widgets.HBox(i.children[:2])\n",
    "    display(hbox)\n",
    "    hbox.on_displayed(InteractionAnalytics.pca_3d(df,cols_list,col1=w1.value,col2=w2.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('dublinbusenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "4fe223dfabe6e78d0cfebc981f530225a4718df0bdd9404c6c77a4c2434ce4f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
